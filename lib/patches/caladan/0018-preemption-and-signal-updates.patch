From 386e01ad509c72cd30b64663e8d649c6b708331c Mon Sep 17 00:00:00 2001
From: Josh Fried <joshuafried@gmail.com>
Date: Mon, 10 Jul 2023 03:17:58 -0400
Subject: [PATCH 18/35] preemption and signal updates

---
 inc/runtime/thread.h |  4 +---
 runtime/cfg.c        |  8 --------
 runtime/defs.h       |  2 +-
 runtime/preempt.c    | 31 +++++++++++--------------------
 runtime/sched.c      | 39 +++++++++++++++++++++++++++++----------
 5 files changed, 42 insertions(+), 42 deletions(-)

diff --git a/inc/runtime/thread.h b/inc/runtime/thread.h
index cb909c0..9672efd 100644
--- a/inc/runtime/thread.h
+++ b/inc/runtime/thread.h
@@ -108,7 +108,6 @@ struct stack;
 struct thread {
     struct thread_tf    tf;
     struct list_node    link;
-    struct stack        *syscallstack;
     struct stack        *stack;
     unsigned int        main_thread:1;
     unsigned int        has_fsbase:1;
@@ -120,8 +119,7 @@ struct thread {
     uint64_t        tlsvar;
      // Trapframe used by junction to stash registers on syscall entry
     struct thread_tf	junction_tf;
-    void 		*xsave_area;
-    unsigned long    junction_tstate_buf[8];
+    unsigned long    junction_tstate_buf[24];
 #ifdef GC
     struct list_node    gc_link;
     unsigned int        onk;
diff --git a/runtime/cfg.c b/runtime/cfg.c
index 378fa31..21e76b1 100644
--- a/runtime/cfg.c
+++ b/runtime/cfg.c
@@ -19,7 +19,6 @@ static size_t arp_static_sz;
 size_t arp_static_count;
 struct cfg_arp_static_entry *static_entries;
 int preferred_socket = 0;
-bool use_sigaltstack = false;
 
 /*
  * Configuration Options
@@ -365,13 +364,6 @@ static int parse_enable_transparent_hugepages(const char *name, const char *val)
   return 0;
 }
 
-static int parse_use_sigaltstack(const char *name, const char *val)
-{
-	use_sigaltstack = true;
-	log_warn("cfg: using sigaltstack, preemption is not supported");
-	return 0;
-}
-
 /*
  * Parsing Infrastructure
  */
diff --git a/runtime/defs.h b/runtime/defs.h
index fca8e48..6c098e4 100644
--- a/runtime/defs.h
+++ b/runtime/defs.h
@@ -70,6 +70,7 @@ struct stack {
 };
 
 DECLARE_PERTHREAD(struct tcache_perthread, stack_pt);
+DECLARE_PERTHREAD(void *, runtime_stack);
 
 /**
  * stack_alloc - allocates a stack
@@ -455,7 +456,6 @@ extern unsigned int cfg_request_hardware_queues;
 extern uint64_t cfg_ht_punish_us;
 extern uint64_t cfg_qdelay_us;
 extern uint64_t cfg_quantum_us;
-extern bool use_sigaltstack;
 
 extern void kthread_park(void);
 extern void kthread_park_now(void);
diff --git a/runtime/preempt.c b/runtime/preempt.c
index 9ac73f8..f49d73e 100644
--- a/runtime/preempt.c
+++ b/runtime/preempt.c
@@ -4,6 +4,7 @@
 
 #include <signal.h>
 #include <string.h>
+#include <ucontext.h>
 
 #include <asm/prctl.h>
 #include <immintrin.h>
@@ -43,6 +44,8 @@ static __nofp inline void set_preempt_needed(void)
 /* handles preemptive cede signals from the iokernel */
 static void handle_sigusr1(int s, siginfo_t *si, void *c)
 {
+	ucontext_t *ctx = (ucontext_t *)c;
+
 	STAT(PREEMPTIONS)++;
 
 	/* resume execution if preemption is disabled */
@@ -53,6 +56,9 @@ static void handle_sigusr1(int s, siginfo_t *si, void *c)
 
 	WARN_ON_ONCE(!preempt_cede_needed(myk()));
 
+	// prevent sigreturn from updating altstack
+	ctx->uc_stack.ss_flags = 4;
+
 	preempt_disable();
 	thread_cede();
 }
@@ -60,6 +66,8 @@ static void handle_sigusr1(int s, siginfo_t *si, void *c)
 /* handles preemptive yield signals from the iokernel */
 static void handle_sigusr2(int s, siginfo_t *si, void *c)
 {
+	ucontext_t *ctx = (ucontext_t *)c;
+
 	STAT(PREEMPTIONS)++;
 
 	/* resume execution if preemption is disabled */
@@ -72,6 +80,9 @@ static void handle_sigusr2(int s, siginfo_t *si, void *c)
 	if (!preempt_yield_needed(myk()))
 		return;
 
+	// prevent sigreturn from updating altstack
+	ctx->uc_stack.ss_flags = 4;
+
 	thread_yield();
 }
 
@@ -159,25 +170,8 @@ void preempt(void)
 
 int preempt_init_thread(void)
 {
-	stack_t ss;
-	struct stack *stk;
-
 	perthread_store(preempt_cnt, PREEMPT_NOT_PENDING);
 	perthread_store(uintr_stack, (void *)REDZONE_SIZE);
-
-	if (!use_sigaltstack)
-		return 0;
-
-	stk = stack_alloc();
-	if (!stk)
-		return -ENOMEM;
-
-	ss.ss_sp = &stk->usable[0];
-	ss.ss_size = RUNTIME_STACK_SIZE;
-	ss.ss_flags = 0;
-	if (sigaltstack(&ss, NULL) == -1)
-		return -errno;
-
 	return 0;
 }
 
@@ -193,9 +187,6 @@ int preempt_init(void)
 	struct sigaction act;
 	struct cpuid_info regs;
 
-	if (use_sigaltstack)
-		return 0;
-
 	act.sa_flags = SA_SIGINFO | SA_NODEFER;
 
 	if (sigemptyset(&act.sa_mask) != 0) {
diff --git a/runtime/sched.c b/runtime/sched.c
index 32fdc84..9d7f1da 100644
--- a/runtime/sched.c
+++ b/runtime/sched.c
@@ -3,6 +3,7 @@
  */
 
 #include <sched.h>
+#include <signal.h>
 #include <immintrin.h>
 
 #include <base/stddef.h>
@@ -21,7 +22,7 @@
 /* the current running thread, or NULL if there isn't one */
 DEFINE_PERTHREAD(thread_t *, __self);
 /* a pointer to the top of the per-kthread (TLS) runtime stack */
-static DEFINE_PERTHREAD(void *, runtime_stack);
+DEFINE_PERTHREAD(void *, runtime_stack);
 DEFINE_PERTHREAD(uint64_t, runtime_fsbase);
 /* Flag to prevent watchdog from running */
 bool disable_watchdog;
@@ -723,7 +724,26 @@ void thread_ready_head(thread_t *th)
 	putk();
 }
 
-static void thread_finish_cede(void)
+void thread_finish_yield(void)
+{
+	thread_t *curth = thread_self();
+	struct kthread *k = myk();
+
+	assert_preempt_disabled();
+
+	spin_lock(&k->lock);
+
+	/* check for softirqs */
+	softirq_run_locked(k);
+
+	curth->thread_ready = false;
+	curth->last_cpu = k->curr_cpu;
+	thread_ready_locked(curth);
+
+	schedule();
+}
+
+void thread_finish_cede(void)
 {
 	struct kthread *k = myk();
 	thread_t *myth = thread_self();
@@ -809,17 +829,11 @@ static __always_inline thread_t *__thread_create(void)
 	preempt_enable();
 
 	th->stack = s;
-	th->syscallstack = stack_alloc();
-
-	BUG_ON(!th->syscallstack);
-
-
 	th->main_thread = false;
 	th->has_fsbase = false;
 	th->thread_ready = false;
 	th->thread_running = false;
 	th->tlsvar = 0;
-	th->xsave_area = NULL;
 
 	return th;
 }
@@ -916,8 +930,6 @@ void thread_free(thread_t *th)
 {
 	gc_remove_thread(th);
 	stack_free(th->stack);
-	if (th->syscallstack)
-		stack_free(th->syscallstack);
 	tcache_free(perthread_ptr(thread_pt), th);
 }
 
@@ -994,6 +1006,7 @@ static void runtime_top_of_stack(void)
  */
 int sched_init_thread(void)
 {
+	stack_t ss;
 	struct stack *s;
 
 	tcache_init_perthread(thread_tcache, perthread_ptr(thread_pt));
@@ -1005,6 +1018,12 @@ int sched_init_thread(void)
 	perthread_store(runtime_stack, (void *)stack_init_to_rsp(s, runtime_top_of_stack));
 	perthread_store(runtime_fsbase, _readfsbase_u64());
 
+	ss.ss_sp = &s->usable[0];
+	ss.ss_size = RUNTIME_STACK_SIZE;
+	ss.ss_flags = 0;
+	if (sigaltstack(&ss, NULL) == -1)
+		return -errno;
+
 	return 0;
 }
 
-- 
2.43.0

