From 5fc0295ca20a67f4cc641af6b0fd94d38bb4afda Mon Sep 17 00:00:00 2001
From: Josh Fried <joshuafried@gmail.com>
Date: Mon, 10 Jul 2023 03:17:58 -0400
Subject: [PATCH 18/35] preemption and signal updates

---
 inc/runtime/thread.h |  4 +---
 runtime/cfg.c        |  8 --------
 runtime/defs.h       |  2 +-
 runtime/preempt.c    | 20 --------------------
 runtime/sched.c      | 39 +++++++++++++++++++++++++++++----------
 5 files changed, 31 insertions(+), 42 deletions(-)

diff --git a/inc/runtime/thread.h b/inc/runtime/thread.h
index 8772d0ce..18dcc673 100644
--- a/inc/runtime/thread.h
+++ b/inc/runtime/thread.h
@@ -57,7 +57,6 @@ struct stack;
 struct thread {
     struct thread_tf    tf;
     struct list_node    link;
-    struct stack        *syscallstack;
     struct stack        *stack;
     unsigned int        main_thread:1;
     unsigned int        has_fsbase:1;
@@ -70,8 +69,7 @@ struct thread {
     uint64_t        tlsvar;
      // Trapframe used by junction to stash registers on syscall entry
     struct thread_tf	junction_tf;
-    void 		*xsave_area;
-    unsigned long    junction_tstate_buf[8];
+    unsigned long    junction_tstate_buf[24];
 #ifdef GC
     struct list_node    gc_link;
     unsigned int        onk;
diff --git a/runtime/cfg.c b/runtime/cfg.c
index c88d746a..552fcbe9 100644
--- a/runtime/cfg.c
+++ b/runtime/cfg.c
@@ -19,7 +19,6 @@ static size_t arp_static_sz;
 size_t arp_static_count;
 struct cfg_arp_static_entry *static_entries;
 int preferred_socket;
-bool use_sigaltstack = false;
 
 /*
  * Configuration Options
@@ -365,13 +364,6 @@ static int parse_enable_transparent_hugepages(const char *name, const char *val)
   return 0;
 }
 
-static int parse_use_sigaltstack(const char *name, const char *val)
-{
-	use_sigaltstack = true;
-	log_warn("cfg: using sigaltstack, preemption is not supported");
-	return 0;
-}
-
 /*
  * Parsing Infrastructure
  */
diff --git a/runtime/defs.h b/runtime/defs.h
index 69043666..b5e1567a 100644
--- a/runtime/defs.h
+++ b/runtime/defs.h
@@ -72,6 +72,7 @@ struct stack {
 };
 
 DECLARE_PERTHREAD(struct tcache_perthread, stack_pt);
+DECLARE_PERTHREAD(void *, runtime_stack);
 
 /**
  * stack_alloc - allocates a stack
@@ -457,7 +458,6 @@ extern unsigned int cfg_request_hardware_queues;
 extern uint64_t cfg_ht_punish_us;
 extern uint64_t cfg_qdelay_us;
 extern uint64_t cfg_quantum_us;
-extern bool use_sigaltstack;
 
 extern void kthread_park(void);
 extern void kthread_park_now(void);
diff --git a/runtime/preempt.c b/runtime/preempt.c
index 0ec08ad5..a0c2dbba 100644
--- a/runtime/preempt.c
+++ b/runtime/preempt.c
@@ -162,25 +162,8 @@ void preempt(void)
 
 int preempt_init_thread(void)
 {
-	stack_t ss;
-	struct stack *stk;
-
 	perthread_store(preempt_cnt, PREEMPT_NOT_PENDING);
 	perthread_store(uintr_stack, (void *)REDZONE_SIZE);
-
-	if (!use_sigaltstack)
-		return 0;
-
-	stk = stack_alloc();
-	if (!stk)
-		return -ENOMEM;
-
-	ss.ss_sp = &stk->usable[0];
-	ss.ss_size = RUNTIME_STACK_SIZE;
-	ss.ss_flags = 0;
-	if (sigaltstack(&ss, NULL) == -1)
-		return -errno;
-
 	return 0;
 }
 
@@ -196,9 +179,6 @@ int preempt_init(void)
 	struct sigaction act;
 	struct cpuid_info regs;
 
-	if (use_sigaltstack)
-		return 0;
-
 	act.sa_flags = SA_SIGINFO | SA_NODEFER;
 
 	if (sigemptyset(&act.sa_mask) != 0) {
diff --git a/runtime/sched.c b/runtime/sched.c
index 0e46a133..77edfc9e 100644
--- a/runtime/sched.c
+++ b/runtime/sched.c
@@ -3,6 +3,7 @@
  */
 
 #include <sched.h>
+#include <signal.h>
 #include <immintrin.h>
 
 #include <base/stddef.h>
@@ -21,7 +22,7 @@
 /* the current running thread, or NULL if there isn't one */
 DEFINE_PERTHREAD(thread_t *, __self);
 /* a pointer to the top of the per-kthread (TLS) runtime stack */
-static DEFINE_PERTHREAD(void *, runtime_stack);
+DEFINE_PERTHREAD(void *, runtime_stack);
 DEFINE_PERTHREAD(uint64_t, runtime_fsbase);
 /* Flag to prevent watchdog from running */
 bool disable_watchdog;
@@ -723,7 +724,26 @@ void thread_ready_head(thread_t *th)
 	putk();
 }
 
-static void thread_finish_cede(void)
+void thread_finish_yield(void)
+{
+	thread_t *curth = thread_self();
+	struct kthread *k = myk();
+
+	assert_preempt_disabled();
+
+	spin_lock(&k->lock);
+
+	/* check for softirqs */
+	softirq_run_locked(k);
+
+	curth->thread_ready = false;
+	curth->last_cpu = k->curr_cpu;
+	thread_ready_locked(curth);
+
+	schedule();
+}
+
+void thread_finish_cede(void)
 {
 	struct kthread *k = myk();
 	thread_t *myth = thread_self();
@@ -809,17 +829,11 @@ static __always_inline thread_t *__thread_create(void)
 	preempt_enable();
 
 	th->stack = s;
-	th->syscallstack = stack_alloc();
-
-	BUG_ON(!th->syscallstack);
-
-
 	th->main_thread = false;
 	th->has_fsbase = false;
 	th->thread_ready = false;
 	th->thread_running = false;
 	th->tlsvar = 0;
-	th->xsave_area = NULL;
 
 	return th;
 }
@@ -916,8 +930,6 @@ void thread_free(thread_t *th)
 {
 	gc_remove_thread(th);
 	stack_free(th->stack);
-	if (th->syscallstack)
-		stack_free(th->syscallstack);
 	tcache_free(perthread_ptr(thread_pt), th);
 }
 
@@ -994,6 +1006,7 @@ static void runtime_top_of_stack(void)
  */
 int sched_init_thread(void)
 {
+	stack_t ss;
 	struct stack *s;
 
 	tcache_init_perthread(thread_tcache, perthread_ptr(thread_pt));
@@ -1005,6 +1018,12 @@ int sched_init_thread(void)
 	perthread_store(runtime_stack, (void *)stack_init_to_rsp(s, runtime_top_of_stack));
 	perthread_store(runtime_fsbase, _readfsbase_u64());
 
+	ss.ss_sp = &s->usable[0];
+	ss.ss_size = RUNTIME_STACK_SIZE;
+	ss.ss_flags = 0;
+	if (sigaltstack(&ss, NULL) == -1)
+		return -errno;
+
 	return 0;
 }
 
-- 
2.43.0

