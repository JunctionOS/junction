From ac498b4846097700ad11b738df9bc4bb5d946010 Mon Sep 17 00:00:00 2001
From: "girfan@mit.edu" <girfan@mit.edu>
Date: Tue, 31 Jan 2023 13:12:33 -0500
Subject: [PATCH 13/40] Do not call mbind in __mem_map_anom

---
 base/mem.c  |  2 ++
 base/page.c |  2 +-
 base/slab.c | 10 +++++-----
 3 files changed, 8 insertions(+), 6 deletions(-)

diff --git a/base/mem.c b/base/mem.c
index cb87d99..e064b8d 100644
--- a/base/mem.c
+++ b/base/mem.c
@@ -88,10 +88,12 @@ __mem_map_anom(void *base, size_t len, size_t pgsize,
 	if ((intptr_t)addr < 0)
 		return MAP_FAILED;
 
+  /*
 	BUILD_ASSERT(sizeof(unsigned long) * 8 >= NNUMA);
 	if (syscall_mbind(addr, len, numa_policy, mask ? mask : NULL,
 		  mask ? NNUMA + 1 : 0, MPOL_MF_STRICT | MPOL_MF_MOVE))
 		goto fail;
+  */
 
 	if (cfg_transparent_hugepages_enabled && (pgsize > PGSIZE_4KB)) {
 	  if (madvise(addr, len, MADV_HUGEPAGE))
diff --git a/base/page.c b/base/page.c
index 27dde0e..9f1adef 100644
--- a/base/page.c
+++ b/base/page.c
@@ -354,7 +354,7 @@ int page_init(void)
 	addr = (void *)align_up((uintptr_t)addr, PGSIZE_2MB);
 
 	/* Then map NUMA-local large pages on top. */
-	for (i = 0; i < numa_count; i++) {
+	for (i = 0; i < 1; i++) {
 		node = &lgpage_nodes[i];
 		node->tbl = mem_map_anom(
 			(char *)addr + i * LGPAGE_META_LEN,
diff --git a/base/slab.c b/base/slab.c
index e0fb518..6241255 100644
--- a/base/slab.c
+++ b/base/slab.c
@@ -90,7 +90,7 @@ __slab_create(struct slab *s, const char *name, size_t size,
 	struct slab_node *n;
 	int i;
 
-	for (i = 0; i < numa_count; i++) {
+	for (i = 0; i < 1; i++) {
 		n = (struct slab_node *)slab_alloc_on_node(&node_slab, i);
 		if (!n)
 			goto fail;
@@ -119,7 +119,7 @@ __slab_early_create(struct slab *s, struct slab_node *nodes,
 {
 	int i;
 
-	for (i = 0; i < numa_count; i++) {
+	for (i = 0; i < 1; i++) {
 		__slab_create_node(&nodes[i], i, size, offset, flags, nr_elems);
 		s->nodes[i] = &nodes[i];
 	}
@@ -136,7 +136,7 @@ static int __slab_early_migrate(struct slab *s)
 	struct slab_node *n;
 	int i;
 
-	for (i = 0; i < numa_count; i++) {
+	for (i = 0; i < 1; i++) {
 		n = (struct slab_node *)slab_alloc_on_node(&node_slab, i);
 		if (!n)
 			goto fail;
@@ -204,7 +204,7 @@ void slab_destroy(struct slab *s)
 	list_del(&s->link);
 	spin_unlock(&slab_lock);
 
-	for (i = 0; i < numa_count; i++) {
+	for (i = 0; i < 1; i++) {
 		__slab_destroy_node(s->nodes[i]);
 		slab_free(&node_slab, s->nodes[i]);
 	}
@@ -460,7 +460,7 @@ void slab_print_usage(void)
 	list_for_each(&slab_list, s, link) {
 		size_t usage = 0;
 
-		for (i = 0; i < numa_count; i++) {
+		for (i = 0; i < 1; i++) {
 			struct slab_node *n = s->nodes[i];
 
 			if (n->flags & SLAB_FLAG_LGPAGE) {
-- 
2.43.0

